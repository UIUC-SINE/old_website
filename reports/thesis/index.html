<!DOCTYPE html>
<html lang=en>

<head>
  <title>Thesis Introduction Draft</title>
  <meta name="viewport" content="width=device-width">
  <link rel="stylesheet" type="text/css" href="/styles.css" /> 
  <link rel="stylesheet" type="text/css" href="/codehilite.css" /> 
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous"> 
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script> 
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body,{delimiters: [{left: '```math', right: '```', display: true}, {left: '$', right: '$', display: false}]});"></script>  

</head>
<body>
<main>
  <article>
    <header>
      <h1>Thesis Introduction Draft</h1>
      <time datetime="2019-06-16">2019-06-16</time>
    </header>
    <div class="toc">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#area-based-registration">Area based Registration</a><ul>
<li><a href="#correlation-like-methods">Correlation-like Methods</a><ul>
<li><a href="#cross-correlation">Cross Correlation</a></li>
<li><a href="#generalized-iterative-cross-correlation">Generalized Iterative Cross Correlation</a></li>
<li><a href="#selective-similary-detection-algorithm-ssda">Selective Similary Detection Algorithm (SSDA)</a></li>
</ul>
</li>
<li><a href="#frequency-based">Frequency Based</a><ul>
<li><a href="#phase-correlation">Phase Correlation</a></li>
<li><a href="#de-castro-morandi-method">De Castro, Morandi Method</a></li>
<li><a href="#phase-correlation-rotationscale-extension">Phase Correlation - Rotation/Scale Extension</a></li>
<li><a href="#phase-correlation-subpixel-registration-extension">Phase Correlation - Subpixel Registration Extension</a></li>
</ul>
</li>
<li><a href="#information-based">Information Based</a><ul>
<li><a href="#mutual-information">Mutual Information</a></li>
</ul>
</li>
<li><a href="#optimization-based">Optimization Based</a><ul>
<li><a href="#nmsre-conjugate-descent">NMSRE Conjugate Descent</a></li>
<li><a href="#gauss-newton-minimization">Gauss-Newton Minimization</a></li>
<li><a href="#levenberg-marquardt">Levenberg-Marquardt</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#feature-based-registration">Feature Based Registration</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>
<h1 id="introduction">Introduction</h1>
<p>Image registration is the process of overlaying two images of the same scene taken at different times, different viewpoints, or with different imaging equipment.  Registration is an important step in countless fields in remote sensing.  Geographic information systems (GIS), medical computer tomography (CT), cartography and computer vision all make extensive use of image registration for the purposes of image fusion and denoising, change detection or super-resolution.</p>
<p>Let $I_1$ and $I_2$ be two images captured of a scene.  These are often called the <em>reference</em> and <em>template</em> images.  In image registration, we want to find a mapping from regions in the template image to regions in the reference image.  More formally, we want to find $f$ such that</p>
<p>```math
I_2(x) = g(I_1(f(x))) \,\, \forall x \in X
```</p>

<p>where $x$ is a 2D coordinate in the image overlap region $X$, $f$ is some unknown coordinate transform, and $g$ is an unknown intensity mapping function.  In the simple case, $g$ is often assumed to be unitary, but can be a very complicated function in multimodal applications like medical imaging where $I_1$ and $I_2$ are captured from different instruments.</p>
<p><em>Zitova, Flusser 2003</em> generalizes all image registration algorithms into 4 steps.  Note that certain algorithms omit some of these steps.</p>
<ol>
<li><strong>Feature detection</strong> - Distinct features (points, edges, closed regions, intersections, corners, etc.) are detected in both images.  These features may be represented by coordinates (intersections, corners, etc.), coordinate pairs (edges) or a more complex parameterization.  This step is omitted in area based registration methods.</li>
<li><strong>Feature Matching</strong> - Correspondence is established between features detected in the images.  Feature similarity measures or feature positions within the images may be used to do this.  This step is omitted in area based registration methods.</li>
<li><strong>Transform model estimation</strong> - The parameters of the coordinate mapping function $f$ are computed using the previously matched features.</li>
<li><strong>Image transformation</strong> - The sensed image is transformed using the estimated parameters and optionally fused with the template image.  Interpolation may be necessary if the mapping function contains non-integer coordinates.</li>
</ol>
<p>In the next section, I highlight some classical and/or popular contemporary image registration methods and the domains in which they are applied.</p>
<h1 id="area-based-registration">Area based Registration</h1>
<p>There are two overarching categories of image registration algorithms, area based and feature based.  Area based methods perform no feature detection or feature mapping and instead use all available pixels in the feature matching step <!-- not necessarily true --> to register the images.  Most classical registration methods fall into this category and they are relatively simpler than feature based methods as a result.</p>
<p>This simplicity can sometimes come at a performance cost in certain situations, however.  If a target scene has smooth regions with few salient features to register on, an area based method may perform more poorly than a feature based method which can ignore the smooth parts of the scene that contain little alignment information.</p>
<h3 id="correlation-like-methods">Correlation-like Methods</h3>
<h5 id="cross-correlation">Cross Correlation</h5>
<p>The most straightforward of all methods, direct correlation only works when $f$ is a simple linear translation, $f(x) = x - c$.</p>
<p>```math
f^* = \arg \max_{\hat{f} \in F} \frac{\sum_{x \in X} I_1(x)I_2(\hat{f}(x))}{\sqrt{\sum_{x \in X} I_1(x)^2}}
```</p>

<p>where $F$ is the set of all linear translations.</p>
<p>Stated more simply</p>
<p>```math
c^* = \arg \max_{\hat{c}} \frac{\sum_{x \in X} I_1(x)I_2(x - \hat{c})}{\sqrt{\sum_{x \in X} I_1(x)^2}}
```</p>

<p>Note that the normalization here is crucial so that the intensities of $I_1$ and $I_2$ do not influence the maximum.  We call this measure normalized cross correlation (NCC).
<!-- <code>math --&gt;
&lt;!-- f^* = \arg \max_{\hat{f}} \sum_x I_1(x)I_2(\hat{f}(x)) = \arg \min_{\hat{f}} \sum_x e(x)^2 --&gt;
&lt;!--</code> --></p>
<p>In practice, cross correlation is still successful in the presence of slight rotation or scaling.</p>
<p>Related similarity measures which are sometimes used in place of normalized cross correlation are sum of squared error (SSE)</p>
<p>```math
\sum_{x \in X} (I_1(x) - I_2(x - \hat{c}))^2
```</p>

<p>and correlation coefficient</p>
<p>```math
\frac{\text{cov}(I_1, I_2)}{\sigma_1 \sigma_2} = \frac{\sum_{x \in X} (I_1(x) - \mu_1)(I_2(x - \hat{c}) - \mu_2)}{\sqrt{\sum_{x \in X} (I_1(x) - \mu_1)^2 \sum_{x \in X}(I_2(x - \hat{c}) - \mu_2)^2}}
```</p>

<p>where $\mu_1$ and $\mu_2$ are the means of $I_1$ and $I_2$ in $X$.</p>
<h5 id="generalized-iterative-cross-correlation">Generalized Iterative Cross Correlation</h5>
<h5 id="selective-similary-detection-algorithm-ssda">Selective Similary Detection Algorithm (SSDA)</h5>
<p>In standard correlation methods, the sum over $X$ for each candidate $\hat{f}$ must be computed in full before a maximum is found.  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5008923">Barnea, Silverman 1972</a> proposes a class alternative schemes which greatly improve computation time in two ways.  The paper calls these algorithms selective similarity detection algorithms (SSDAs), of which one is presented here.</p>
<p>First, the paper uses absolute sum of errors (ASE) as a similarity measure, which requires no costly multiplications unlike NCC or SSE.</p>
<p>```math
\sum_{x \in X} |I_1(x) - I_2(x - \hat{c})|
```</p>

<p>The second optimization uses early stopping and requires that the above sum over $X$ be implemented sequentially (e.g. as an iterative software loop).  For a particular candidate $\hat{c}$, the current value of the in-progress ASE is compared to a threshold parameter after each summand.  If the ASE surpasses this threshold, the number of iterations is recorded and the algorithm moves on to the next candidate.  If an candidate computation never exceeds $T$, then the final ASE is recorded instead.</p>
<p>Finally, the candidate with the lowest ASE is selected.  If all candidates surpassed the threshold, then the candidate with the most number of iterations before passing the threshold is selected.</p>
<p><figure alt="Error accumulation curves for candidates $\hat{c}_1$, $\hat{c}_2$, $\hat{c}_3$ and $\hat{c}_4$.  Error computation for $\hat{c}_1$ and $\hat{c}_2$ terminated early at 7 and 9 iterations.  $\hat{c}_4$ is the best estimate for offset, followed by $\hat{c}_3$, $\hat{c}_2$ and $\hat{c}_1$."><img src="ssda.png" /><figcaption>Error accumulation curves for candidates $\hat{c}_1$, $\hat{c}_2$, $\hat{c}_3$ and $\hat{c}_4$.  Error computation for $\hat{c}_1$ and $\hat{c}_2$ terminated early at 7 and 9 iterations.  $\hat{c}_4$ is the best estimate for offset, followed by $\hat{c}_3$, $\hat{c}_2$ and $\hat{c}_1$.</figcaption></figure></p>
<p>This algorithm offers potentially orders of magnitude speed improvements over direct cross-correlation because of early stopping, but requires selection of parameter $T$.  A choice of $T$ too high limits efficiency gains while a choice of $T$ too low can lead to suboptimal results.</p>
<h3 id="frequency-based">Frequency Based</h3>
<p>If an acceleration over correlation based methods is needed or the images were acquired under frequency dependent noise, Fourier methods are often preferred.  These methods exploit the Fourier representation of methods in the frequency domain and have shown better robustness against non-uniform illumination differences between $I_1$ and $I_2$.</p>
<h5 id="phase-correlation">Phase Correlation</h5>
<p>Phase correlation was originally proposed for registering linearly translated images.  It takes advantage of the Fourier Shift theorem, which states that translating an image and taking its Fourier transform is equivalent to multiplying the Fourier transform of the original untranslated image by a complex exponential.</p>
<p>Computing the cross-power spectral density (CPSD) we can directly obtain this complex exponential.</p>
<p>```math
\frac{\tilde{I_1}(\omega) \tilde{I_2}(\omega)}{|\tilde{I_1}(\omega) \overline{\tilde{I_2}(\omega)}|} =
\frac{\tilde{I_1}(\omega) \tilde{I_1}(\omega - \hat{c})}{|\tilde{I_1}(\omega) \overline{\tilde{I_1}(\omega - \hat{c})}|} = e^{j \omega \hat{c}}
```</p>

<p>Where the final estimate for $c$ is obtained by a final inverse Fourier transform of the CPSD.</p>
<p>An important consideration here is that the Fourier Shift theorem only holds exactly when translation is circular.  In practice, the phase correlation method still works if the region of overlap is sufficiently large.  <a href="https://ieeexplore.ieee.org/document/988953">Foroosh, Zerubia, Berthod 2002</a> propose a prefilter which can be applied to both images before phase correlation to reduce these effects.</p>
<h5 id="de-castro-morandi-method">De Castro, Morandi Method</h5>
<p><a href="https://ieeexplore.ieee.org/document/4767966">De Castro, Morandi 1987</a> introduced a method of</p>
<!-- FIXME need a notational correction here, there are continuous and discrete versions of I in both time and frequency that need to be expressed -->

<p>```math
\tilde{I}(\omega_x, \omega_y) = \int_X I(x, y) e^{-j(x \omega_x + y \omega_y)} dx\, dy \approx \Delta x \Delta y \tilde{I}(\omega_x, \omega_y)
```</p>

<p>```math

```</p>

<h5 id="phase-correlation-rotationscale-extension">Phase Correlation - Rotation/Scale Extension</h5>
<ul>
<li>fourier-mellin/log-polar transform</li>
</ul>
<h5 id="phase-correlation-subpixel-registration-extension">Phase Correlation - Subpixel Registration Extension</h5>
<ul>
<li>foroosh, subpixel extension</li>
</ul>
<h3 id="information-based">Information Based</h3>
<p>Viola and Wells introduced a new class of registration methods in 1994 based on entropy of image pairs.  This class of methods has proven effective in multimodal registration so it has achieved significant popularity in medical imaging.</p>
<h5 id="mutual-information">Mutual Information</h5>
<p>In the early 20th century, Hartley was looking for a way to measure the transmission of information, particularly in relation to the telegraph as a communications system.  He considered a system in which a finite set of symbols ('dit' or 'dah', telegraph 1's or 0's) are sent sequentially through a channel (telegraph wire).</p>
<p>The number of unique messages that can be encoded given a message lenth of $n$ and $s$ unique symbols is $s^n$.  However, Hartley wanted a measure that would grow linearly with message length.  A message which is twice as long should contain twice as much information.</p>
<p>He therefore settled on the following measure of information:</p>
<p>```math
H = n \log s = \log s^n
```</p>

<p>From the first formulation, it is apparent that information grows linearly with $n$.  Another interesting feature of this measure is that if there is only one symbol, we know exactly what the message will be and so it contains no information $(H = n \log 1 = 0)$.  This suggests that entropy can also be viewed as a measure of uncertainty.</p>
<p>A disadvantage of Hartley's entropy measure is that it assumes all symbols are equally likely to occur in a message, which is generally not true.</p>
<p>In 1948, Shannon introduced a new measure of information which takes this fact into account by weighting Hartley's entropy by the probability that symbols occur.  This is now known as Shannon entropy.  For a set of $s$ symbols with probabilities $p_1, ..., p_s$ of occuring, Shannon entropy is given as</p>
<p>```math
H = \sum_i p_i \log \frac{1}{p_i} = - \sum_i p_i \log p_i
```</p>

<p>Like Hartley's entropy, Shannon entropy can be viewed as a measure of uncertainty.  If a particular symbol has a very high probability of occuring, our uncertainty about the message decreases and hence information decreases.  If all symbols have an equal probability of occuring, entropy is maximized.  Thus Shannon entropy may also be considered as a measure of spread of a probability distribution.  A distribution with most mass concentrated around a few peaks will have low entropy while a more uniform distribution will have higher entropy.</p>
<p>To compute Shannon entropy of an image, all possible intensity values of the pixels can be interpreted as symbols in the message.  For an image with bit depth of 8 bits, one can collect all the intensity values into a histogram in order to compute $p_0, ..., p_{255}$, as shown below.</p>
<p><figure alt="An image and its intensity histogram"><img src="histogram.png" /><figcaption>An image and its intensity histogram</figcaption></figure></p>
<p>Now that we can compute entropy for images we must introduce one more concept before registration can occur, joint histograms.  A joint histogram is a 2D function which, for all possible pairs of intensities, describes how many times intensity pairs occur for a pair of registered images.  For example, if a joint histogram has value 17 at coordinate [33, 34], then for this particular registration there are 17 pixels in which the first image has intensity 33 and the second has intensity 44.  In the case of two registered 8 bit images, the joint histogram is a 256x256 image.  An example joint histogram for two registered images is shown below.</p>
<p><figure alt="Two registered images and their joint histogram, or feature space"><img src="feature_space.png" /><figcaption>Two registered images and their joint histogram, or feature space</figcaption></figure></p>
<p>The joint histogram changes with the alignment of the images.  For a correctly aligned pair of images, structures within the image align and vary with each other, so we expect the intensities to correlate which manifests as clustering in the joint histogram.  As the image pair becomes misaligned, more greyscale combinations are introduced and the joint histogram exhibits more uniformity.  By measuring this uniformity we now have a similarity measure for registration.</p>
<p>Formally, the joint Shannon entropy for a pair of registered images</p>
<p>```math
H(I_1, \hat{I_2}) = -\sum_{i, j} p(i,j) \log p(i, j)
```</p>

<p>where $p(i, j)$ is the joint histogram of $I_1$ and candidate registered $\hat{I_2}$ in the region of overlap $X$. <!-- FIXME --></p>
<p>However, a problem that can occur when joint entropy is used directly is that low entropy (high degree of reported alignment) can occur for invalid registrations if the images contain large regions of uniform intensity.  For example, if the images in the figure above are aligned so that only their corners containing background overlap, the joint histogram will have approximately a single peak and the joint entropy will be very low.  To account for this, one can make use of the marginal entropies to penalize alignments where the region $X$ contains little information in the images.  This is known as mutual information.</p>
<p>```math
MI(I_1, \hat{I_2}) = H(I_1) + H(\hat{I_2}) - H(I_1, \hat{I_2})
```</p>

<ul>
<li>maximize new measure - minimizing joint entropy</li>
<li>penalizes low information in X</li>
<li></li>
</ul>
<p>With this new measure, if the overlap region contains little information, terms $H(I_1)$ and $H(\hat{I_2})$ will be small and counteract joint entropy.  Also note that since mutual information contains $-H(I_1, \hat{I_2})$, minimizing joint entropy is related to maximizing mutual information.</p>
<h3 id="optimization-based">Optimization Based</h3>
<p>Many of the above methods introduce various similarity metrics as measures of alignment between registration candidates.  They mostly rely on an exhaustive search through all potential registration candidates and as such are restricted to situations where the set of all possible $\hat{f}$ candidates are small, usually simple translation.  In situations where the number of parameters controlling $f$ is large, such as elastic transformation, it is appropriate to make use optimization methods that can find minima or maxima in the chosen similarity measure in a feasible amount of time.</p>
<h5 id="nmsre-conjugate-descent">NMSRE Conjugate Descent</h5>
<!-- FIXME assumes linear shift, but this section is about high dimensional f -->

<p>The first method, presented by <a href="https://www.osapublishing.org/ol/viewmedia.cfm?uri=ol-33-2-156&amp;seq=0">Guizar-Sicairos, Thurman, Fienup 2008</a>,  is a form of conjugate descent on the normalized root mean squared error (NRMSE), which is a translation-invariant measure of error between an image $f$ and a copy $g$ shifted by $(x_0^{\ast}, y_0^*)$.</p>
<p>```math
f^*_{NMSRE} = \min_{\hat{f}} \frac{\sum_{x} |I_2(\hat{f}(x)) - I_1(x)|^2}{\sum_{x}|I_1(x)|^2}
```</p>

<p>By minimizing the NMSRE over $f$, the true parameters of $f$ can be found.</p>
<p>Rewriting the above definition into a maximization problem and assuming $f$ is a linear shift by $[x_0, y_0]$, we can achieve a more useful formulation.</p>
<p>```math
NMSRE^2 = 1 - \frac{\max_{x_0, y_0} |r(x_0, y_0)|^2}{\sum_{x, y}|I_1(x, y)|^2 \sum_{x, y}|I_2(x, y)|^2} \\

\begin{aligned}
r(x_0, y_0) &= \sum_{x, y}I_2(x - x_0, y - y_0)I_1^*(x, y) \\
&= \sum_{u, v} \tilde{I_1}(u, v)\tilde{I_2}^*(u, v) \text{exp}\left[ j 2 \pi \left( u \frac{x_0}{M} + v \frac{y_0}{N} \right) \right]
\end{aligned}
```</p>

<p>where $r$ is cross correlation and $\tilde{I_1}$ and $\tilde{I_2}$ are the image DFTs of size $M \times N$.</p>
<p>Since all other terms are constant, we need only minimize $|r(x_0, y_0)|^2$.</p>
<p>```math
\frac{d(r(x_0, y_0))}{dx_0} = 2 \text{Im} \left(r(x_0, y_0) \sum_{u, v} \frac{2 \pi u}{M} \tilde{I_1}^*(u, v) \times \tilde{I_2}(u, v) \text{exp} \left[-j 2 \pi \left( u \frac{x_0}{M} + v \frac{y_0}{N} \right) \right] \right)
```</p>

<p>With this partial derivative (and a similar for $y_0$) we can use standard conjugate descent to solve for $(x_0^{\ast}, y_0^*)$.</p>
<h5 id="gauss-newton-minimization">Gauss-Newton Minimization</h5>
<h5 id="levenberg-marquardt">Levenberg-Marquardt</h5>
<h1 id="feature-based-registration">Feature Based Registration</h1>
<h1 id="summary">Summary</h1>
<p>Area based methods are preferred when images have salient details and information is provided by pixel intensities rather than shapes and structures in the imae.  The images' intensities must be similar or at least statistically ..  The set of candidate $f$ that can be searched is generally limited to translation with small amounts of rotation or skew, but there are some extensions to methods that support large rotations or skews so long as the degrees of freedom of $f$ remains small.  Pyramid search techniques and sophisticated optimization strategies are available to more quickly find extrema of the similarity measure.</p>
<p>Feature based methods are generally utilized when shapes in structures in the image pair contain more alignment information than the pixel intensities, such as between a picture of an object and a computer model of an object.  The drawback of these methods is that such features can be hard to detect and match with each other.  It is critical that chosen feature detector be robust against any differences between the images.</p>
<h1 id="references">References</h1>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0262885603001379/pdfft?md5=9ac6884a88ac624d4861de8fe7666e27&amp;pid=1-s2.0-S0262885603001379-main.pdf">Image registration methods: a survey</a> - Zitova, Flusser 2003</li>
<li><a href="https://www.google.com/search?q=survey%20of%20mutual%20information%20based%20registration">A Survey of Mutual Information Based Registration</a> - Pluim, Maintz, Viergever 2003</li>
</ul>
  </article>
</main>
<footer>
    <p>SINE UIUC</p>
</footer>
</body>
</html>