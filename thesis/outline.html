<!DOCTYPE html>
<html lang=en>

<head>
    <title>Outline</title>
    <meta name="viewport" content="width=device-width">
    <link rel="stylesheet" type="text/css" href="/styles.css" /> 
    <link rel="stylesheet" type="text/css" href="/codehilite.css" /> 
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/mathtex-script-type.min.js" defer></script> 

</head>
<body>
<main>
  <article>
    <header>
      <h1>Outline</h1>
      <time datetime="2020-04-27">2020-04-27</time>
    </header>
    <!--
- is [^1] equivalent to Prony's method when using all image pixels?
- Guizar-Sicairos multiframe extension
    - can we estimate expected registration error?  [ argmax(sum) ] vs [ mean(argmax, argmax, ...) ]
-->

<style> c { color: gray } </style>

<p>First and second level bullets are sections and subsections.  Third level bullets are further content breakdowns of subsections.</p>
<ul>
<li>Abstract</li>
<li>
<p>Contribution of Thesis</p>
<ul>
<li>Goal: Extend work from <em>Guizar-Sicairos, Thurman, Fienup</em> <sup id="fnref2:5"><a class="footnote-ref" href="#fn:5">3</a></sup> (linear subpixel registration) to a multiframe setting</li>
</ul>
</li>
<li>
<p>Chapter 1 - Introduction</p>
<ul>
<li>Motion Estimation, Segmentation, and Registration<ul>
<li><c>Describe techniques of motion estimation, segmentation, registration.  What fields are they used in (GIS, CT, remote sensing, etc) and related applications. </c></li>
</ul>
</li>
<li>Registration Problem Model<ul>
<li><c>Generic mathematical model for a two-frame registration problem, describing how registration involves finding some specific transform which warps the <em>reference</em> image to the <em>template</em> image.</c></li>
</ul>
</li>
<li>Categorizing Registration Methods<ul>
<li><c> 4 step generalization of registration methods <sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup><ol>
<li>Feature detection</li>
<li>Feature matching</li>
<li>Transform model estimation</li>
<li>Image transformation
</c></li>
</ol>
</li>
</ul>
</li>
<li>Choice of Motion Prior<ul>
<li><c>Describe some families of transforms (translation, rotation, affine, scale, rubbersheeting, etc.) and which are used in some common problems (.e.g rubbersheet transform might be used to align faces of different shapes).  e.g. Mention effects on algorithm complexity.</c></li>
</ul>
</li>
<li>Motivating Problem<ul>
<li><c>1 page description of VISORS project and justification for why this choice of motion prior (constant translation) is appropriate.  Show some simulated images to illustrate extreme observation noise.</c></li>
</ul>
</li>
<li>Outline<ul>
<li><c>Chapter 2 introduces classes of image registration and describes popular registration methods from each class.  Chapter 3 introduces the idea of subpixel registration, its uses, and gives a summary of a fast subpixel registration algorithm which is used to derive a new fast multi-frame subpixel algorithm, described in chapter 4.  Chapter 5 contains numerical registration experiments under various settings, a description of the pipeline used to generate the test images, and some tests involving other classes of images unrelated to the VISORS project.</c></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Chapter 2 - Review of Global Registration Methods</p>
<ul>
<li><c>The primary purpose of this chapter is to overview the classes of registration methods and highlight strenghts and weaknesses. </c></li>
<li>Area Based Methods<ul>
<li><c>Methods include Cross Correlation, Normalized CC and Selective Similarity Detection Algorithm</c></li>
<li><c>Appropriate for situations where high noise immunity is needed.</c></li>
</ul>
</li>
<li>Information Based Methods<ul>
<li><c>Mutual Information</c></li>
</ul>
</li>
<li>Optimization Based Methods<ul>
<li><c>Lukas-Kanade Optical Flow</c></li>
</ul>
</li>
<li>Featured Based Methods<ul>
<li><c>Currently state of the art for handheld video super resolution applications</li>
<li><c>RANSAC</c></li>
<li><c>Features need to be accurately detected and localized -&gt; not good for high noise</c></li>
</ul>
</li>
<li>Frequency Based Methods<ul>
<li><c>Methods include phase correlation, de Castro, Morandi Method <sup id="fnref:5"><a class="footnote-ref" href="#fn:5">3</a></sup></c></li>
<li><c>In the next section I introduce another frequency based method which my work is based upon</c></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Chapter 3 - Subpixel Registration <sup id="fnref2:6"><a class="footnote-ref" href="#fn:6">4</a></sup></p>
<ul>
<li>Coarse Estimation<ul>
<li><c>Coarse estimation step of algorithm.  Just a simple argmax of circular cross correlation implemented via FFTs</c></li>
</ul>
</li>
<li>Fine Estimation<ul>
<li><c>Fine estimation step of algorithm.  Involves direct DFT evaluation of a small patch centered around coarse pixel.</c></li>
</ul>
</li>
<li>Optimality</li>
<li>Padded FFT vs Direct DFT<ul>
<li><c>Explanation of why direct DFT evaluation is significantly faster than a padded FFT approach for the fine estimation step.  Computational complexity analysis?</c></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Chapter 4 - Multiframe Subpixel Registration</p>
<ul>
<li>Multiframe Registration Model<ul>
<li><c>Introduce mathematical model for multiframe registration describing how registration involves finding a set of transforms parameterized by frame number rather than a single transform.</c></li>
</ul>
</li>
<li>Coarse Estimation with All Frames</li>
<li>Fine Estimation with All Frames</li>
<li>Optimality<ul>
<li><c>I have a <a href="/reports/2020-03-07/">partial proof</a> showing that the ML solution to a multiframe registration problem is similar to my algorithm.  Need to revisit this before deciding to include it.</c></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Chapter 5 - Numerical Experiments</p>
<ul>
<li>Generation of Test Data<ul>
<li><c>Nanoflare Scene Generation</c></li>
<li><c>Video Sequence Generation</c><ul>
<li><c>Optical Blurring and Point Spread Functions</c></li>
<li><c>Photon Sieve</c></li>
<li><c>Motion Blurring</c></li>
</ul>
</li>
<li><c>Gaussian and Poisson Noise at Detector</c></li>
</ul>
</li>
<li>Registration Results<ul>
<li><c>Test algorithm under different noise levels, drift velocities, drift angles, framerates, number of frames.</c></li>
<li><c>This would also be the section to compare my algorithm against another multiframe registration algorithm.</c></li>
</ul>
</li>
<li>Other Image Classes<ul>
<li><c>Similar tests on other images unrelated to VISORS to show algorithm is more generally applicable.  These images will have much less noise.</c></li>
<li><c>What are some other scenarios where a constant translation motion prior is appropriate?</c></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Chapter 6 - Conclusion</p>
<ul>
<li>Future Work<ul>
<li>Extension to Rotational Motion <sup id="fnref:8"><a class="footnote-ref" href="#fn:8">5</a></sup></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="timeline">Timeline</h1>
<ul>
<li>May 4 - Introduction completed.<ul>
<li>Some of this introductory material is present in the previous draft.</li>
</ul>
</li>
<li>May 11 - Chapter 3 completed.<ul>
<li>Chapter 3 will be a writeup of the Guizar-Sicairos paper <sup id="fnref:6"><a class="footnote-ref" href="#fn:6">4</a></sup>.</li>
</ul>
</li>
<li>May 25 - Chapter 4 completed.  End of numerical experiments.</li>
<li>June 2 - Chapters 2, 5 completed.  Editing by Farzad begins.<ul>
<li>Much of chapter 2 will come from previous drafts.</li>
<li>Chapter 5 follows the same format as the <a href="https://uiuc-sine.github.io/reports/pipeline/">optics pipeline document</a></li>
</ul>
</li>
<li>July 2 - Last day to start MS thesis check.</li>
<li>July 24 - MS thesis deposit</li>
</ul>
<h1 id="thesis-checklist">Thesis Checklist</h1>
<ul class="checklist">
<li><input type="checkbox" disabled checked> Registered for ECE599</li>
<li><input type="checkbox" disabled> Thesis/Dissertation Approval Form</li>
<li><input type="checkbox" disabled> Apply for graduation</li>
<li><input type="checkbox" disabled> File thesis title with department</li>
<li><input type="checkbox" disabled> Electronic Submission</li>
</ul>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p><a href="https://ieeexplore.ieee.org/abstract/document/988953">Extension of phase correlation to subpixel registration</a> - Foroosh, Zerubia, Berthod&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p><a href="https://www.sciencedirect.com/science/article/pii/S0262885603001379/pdfft?md5=9ac6884a88ac624d4861de8fe7666e27&amp;pid=1-s2.0-S0262885603001379-main.pdf">Image registration methods: a survey</a> - Zitova, Flusser 2003&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:5">
<p><a href="https://ieeexplore.ieee.org/document/4767966">Registration of Translate and Rotated Images Using Finite Fourier Transforms</a> - De Castro, Morandi 1987&#160;<a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 3 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:5" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:6">
<p><a href="https://www.osapublishing.org/ol/viewmedia.cfm?uri=ol-33-2-156&amp;seq=0">Efficient subpixel image registration algorithms</a> - Guizar-Sicairos, thurman, Fienup 2008&#160;<a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 4 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:6" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:8">
<p><a href="http://www.jprr.org/index.php/jprr/article/view/355">Image Registration Using Log Polar Transform and Phase Correlation to Recover Higher Scale</a> - Sarvaiya, Patnaik, Kothari 2012&#160;<a class="footnote-backref" href="#fnref:8" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </article>
</main>
<footer>
    <p>All source code and data available <a href="https://github.com/UIUC-SINE/uiuc-sine.github.io">here</a></p>
    <p>SINE UIUC</p>
</footer>
</body>
</html>